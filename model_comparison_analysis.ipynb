{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5f8577-db77-4b3a-b2ea-a0f61c95a398",
   "metadata": {},
   "source": [
    "## 1. Import Libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2c8f84-d66f-4c7b-89b0-659803a0ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from utils import Skipgram, SkipgramNeg, Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c989239-069b-4a0c-a3ab-3f0a33fcebe5",
   "metadata": {},
   "source": [
    "### Load trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8d40c0-5041-432c-8a33-09b4836f3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_data = pickle.load(open('app/code/models/skipgrams.pkl', 'rb'))\n",
    "skipgram_neg_data = pickle.load(open('app/code/models/skipgrams-neg.pkl', 'rb'))\n",
    "glove_data = pickle.load(open('app/code/models/glove.pkl', 'rb'))\n",
    "\n",
    "skipgram_word2index = skipgram_data['word2index']\n",
    "skipgram_neg_word2index = skipgram_neg_data['word2index']\n",
    "glove_word2index = glove_data['word2index']\n",
    "\n",
    "skipgram_voc_size = skipgram_data['voc_size']\n",
    "skipgram_neg_voc_size = skipgram_neg_data['voc_size']\n",
    "glove_voc_size = glove_data['voc_size']\n",
    "\n",
    "skipgram_emb_size = skipgram_data['emb_size']\n",
    "skipgram_neg_emb_size = skipgram_neg_data['emb_size']\n",
    "glove_emb_size = glove_data['emb_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffb2ed-7118-4250-a0cf-d117512f6af3",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4a2f86-a3ba-43d9-8a71-a2a40975fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('app/code/models/skipgram.pt')\n",
    "# print(\"Keys in saved state_dict:\", checkpoint.keys())\n",
    "# print(\"Keys in model state_dict:\", skipgram.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e94ace2-f9ea-427e-977a-d8f09d4253f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1026588/2492303953.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  skipgram.load_state_dict(torch.load('app/code/models/skipgram.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(18046, 2)\n",
       "  (embedding_outside): Embedding(18046, 2)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram = Skipgram(skipgram_voc_size, skipgram_emb_size, skipgram_word2index)\n",
    "skipgram.load_state_dict(torch.load('app/code/models/skipgram.pt'))\n",
    "skipgram.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1d931a-fa42-4e74-a325-fee8c27cdf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1026588/3623302552.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  skipgramNeg.load_state_dict(torch.load('app/code/models/skipgram-neg.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SkipgramNeg(\n",
       "  (embedding_center): Embedding(18046, 2)\n",
       "  (embedding_outside): Embedding(18046, 2)\n",
       "  (logsigmoid): LogSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgramNeg = SkipgramNeg(skipgram_neg_voc_size, skipgram_neg_emb_size, skipgram_neg_word2index)\n",
    "skipgramNeg.load_state_dict(torch.load('app/code/models/skipgram-neg.pt'))\n",
    "skipgramNeg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ae9a50-a637-473a-a7b7-e53df0729188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1026588/787164419.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  glove.load_state_dict(torch.load('app/code/models/glove.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Glove(\n",
       "  (center_embedding): Embedding(18046, 2)\n",
       "  (outside_embedding): Embedding(18046, 2)\n",
       "  (center_bias): Embedding(18046, 1)\n",
       "  (outside_bias): Embedding(18046, 1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = Glove(glove_voc_size, glove_emb_size, glove_word2index)\n",
    "glove.load_state_dict(torch.load('app/code/models/glove.pt'))\n",
    "glove.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4d6a77-7ce6-4ef0-be5b-21a7a6ef9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = datapath('glove.6B.100d.txt')  #search on the google\n",
    "gensim = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afa4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate semantic and syntactic similarities\n",
    "def evaluate_analogies(analogy_lines, model, word2index):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance on semantic and syntactic analogy tasks.\n",
    "\n",
    "    Args:\n",
    "        analogy_lines (list): List of analogy strings in the format \"word1 word2 word3 word4\".\n",
    "        model: The embedding model (e.g., Skip-gram or GloVe).\n",
    "        word2index (dict): Mapping of words to their indices in the model vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model on the analogy task.\n",
    "    \"\"\"\n",
    "    # Extract vocabulary from word2index\n",
    "    vocabs = list(word2index.keys())\n",
    "\n",
    "    # Prepare embedding vectors for all vocabulary words\n",
    "    all_word_vectors = []\n",
    "    for word in vocabs:\n",
    "        all_word_vectors.append(model.get_embed(word))\n",
    "    all_word_vectors = torch.stack(all_word_vectors)\n",
    "\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Perform vector manipulations for each analogy\n",
    "    for analogy in analogy_lines:\n",
    "        words = analogy.split()\n",
    "\n",
    "        # Assuming the analogy line has four words\n",
    "        vectors = []\n",
    "        for word in words[:3]:  # Only need the first three words for manipulation\n",
    "            if word in vocabs:\n",
    "                vectors.append(model.get_embed(word.lower()))\n",
    "            else:\n",
    "                vectors.append(model.get_embed('<UNK>'))  # Handle unknown words\n",
    "\n",
    "        # Perform vector manipulation (e.g., subtraction and addition)\n",
    "        result_vector = vectors[1] - vectors[0] + vectors[2]\n",
    "\n",
    "        # Add a batch dimension to the result vector\n",
    "        result_vector = result_vector.unsqueeze(0)\n",
    "\n",
    "        # Calculate cosine similarities between the result vector and all vocabulary embeddings\n",
    "        cosine_similarities = F.cosine_similarity(result_vector, all_word_vectors)\n",
    "\n",
    "        # Find the index of the closest word in the vocabulary\n",
    "        closest_word_index = torch.argmax(cosine_similarities).item()\n",
    "        closest_word = vocabs[closest_word_index]\n",
    "\n",
    "        # Check if the predicted word matches the target word (4th word in analogy line)\n",
    "        if closest_word == words[3]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = (correct_predictions / len(analogy_lines)) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4f6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analogy_gensim(analogy_lines, gensim_model):\n",
    "    \"\"\"\n",
    "    Evaluate analogy gensim using a pre-trained gensim model.\n",
    "\n",
    "    Args:\n",
    "        analogy_lines (list): List of analogy questions in the format \"word1 word2 word3 word4\".\n",
    "        gensim_model: The pre-trained gensim word embedding model.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model on the analogy task.\n",
    "    \"\"\"\n",
    "    correct_predictions = 0  # Counter for correct answers\n",
    "\n",
    "    # Process each analogy line\n",
    "    for analogy in analogy_lines:\n",
    "        # Split and preprocess words\n",
    "        words = analogy.split()\n",
    "        processed_words = []\n",
    "        \n",
    "        for word in words:\n",
    "            word = word.lower()  # Convert to lowercase\n",
    "            # Check if the word exists in the gensim model vocabulary\n",
    "            if word in gensim_model:\n",
    "                processed_words.append(word)\n",
    "            else:\n",
    "                processed_words.append('unknown')  # Use 'unknown' for missing words\n",
    "        \n",
    "        # Perform vector arithmetic using the gensim model\n",
    "        try:\n",
    "            most_similar_words = gensim_model.most_similar(\n",
    "                positive=[processed_words[2], processed_words[1]], \n",
    "                negative=[processed_words[0]]\n",
    "            )\n",
    "\n",
    "            # Get the most similar word\n",
    "            predicted_word = most_similar_words[0][0]\n",
    "\n",
    "            # Check if the predicted word matches the target word (4th word)\n",
    "            if predicted_word == processed_words[3]:\n",
    "                correct_predictions += 1\n",
    "        except KeyError:\n",
    "            # Skip analogy if one or more words are missing in the model\n",
    "            continue\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (correct_predictions / len(analogy_lines)) * 100\n",
    "    print(f'Analogy Accuracy: {accuracy:.2f}%')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f722df-ae6c-4876-8e87-76156b3c4a19",
   "metadata": {},
   "source": [
    "## 2. Semantic and Syntatic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4acb8f-b5f7-4d0c-b2f4-91e503968a25",
   "metadata": {},
   "source": [
    "### Load test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d626320a-d0ed-4885-94f8-91bdac143c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read capital-common-countries text file and create a list of tuples\n",
    "with open('test_data/capital-common-countries.txt', 'r') as file:\n",
    "    semantic_analogies = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4999a7e0-a539-429d-96e9-45f1c2044285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read past-tense text file and create a list of tuples\n",
    "with open('test_data/past-tense.txt', 'r') as file:\n",
    "    syntatic_analogies = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c3d28-bb45-4fb0-9be0-c28a80342f82",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3bd7c1f-c51f-4eb3-8f67-0637eb51b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "#skipgram model\n",
    "evaluate_analogies(semantic_analogies, skipgram, skipgram_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f758406e-7f62-488b-9e32-3c85a82d74c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# skipgram negative sampling model\n",
    "evaluate_analogies(semantic_analogies, skipgramNeg, skipgram_neg_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df04718-30b7-4c42-acc1-7836968c607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# glove model\n",
    "evaluate_analogies(semantic_analogies, glove, glove_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059949cd-6f6e-4f76-a198-a7c3f65da84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy Accuracy: 93.87%\n"
     ]
    }
   ],
   "source": [
    "# glove gensim model\n",
    "evaluate_analogy_gensim(semantic_analogies, gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54096d-c736-404e-a72f-aeddd9839ac3",
   "metadata": {},
   "source": [
    "### Syntatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c94d82-1446-4a34-80c8-557742e90ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "#skipgram model\n",
    "evaluate_analogies(syntatic_analogies, skipgram, skipgram_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dcb5a42-d88c-4f39-a980-b37213546f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# skipgram negative sampling model\n",
    "evaluate_analogies(syntatic_analogies, skipgramNeg, skipgram_neg_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e20977-c36b-4753-9df8-2c8cd12a406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# glove model\n",
    "evaluate_analogies(syntatic_analogies, glove, glove_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7435fe02-7e55-4974-866a-c395392315a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy Accuracy: 55.45%\n"
     ]
    }
   ],
   "source": [
    "# glove gensim model\n",
    "evaluate_analogy_gensim(syntatic_analogies, gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85920e19-21c3-4d1c-a44a-e4e338d423e3",
   "metadata": {},
   "source": [
    "## 3. Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fac75c1f-ecfa-46c4-863d-675a20f1e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A.flatten(), B.flatten())\n",
    "    norm_a = np.linalg.norm(A)\n",
    "    norm_b = np.linalg.norm(B)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32a55cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_similarity(lines, model, is_gensim=False):\n",
    "    \"\"\"\n",
    "    Evaluate the similarity between word pairs using a given model.\n",
    "    \n",
    "    Args:\n",
    "        lines (list): List of lines containing word pairs and their similarity scores.\n",
    "                      Each line should be in the format: \"word1 word2 similarity_score\".\n",
    "        model: The word embedding model (e.g., Gensim, PyTorch-based).\n",
    "        is_gensim (bool): Set to True if the model is a Gensim model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Spearman rank correlation (correlation coefficient and p-value).\n",
    "    \"\"\"\n",
    "    scores_real = []  # Store the ground truth similarity scores\n",
    "    scores_pred = []  # Store the model-predicted cosine similarities\n",
    "\n",
    "    # Loop through each line in the dataset\n",
    "    for line in lines:\n",
    "        words = line.split()  # Split the line into components\n",
    "        vec = []  # List to store word vectors\n",
    "\n",
    "        # Extract vectors for the first two words\n",
    "        for word in words[:2]:\n",
    "            try:\n",
    "                if is_gensim:\n",
    "                    # Fetch vector directly for Gensim models\n",
    "                    vec.append(model.get_vector(word))\n",
    "                else:\n",
    "                    # Fetch vector for non-Gensim models\n",
    "                    vec.append(model.get_embed(word).detach().numpy())\n",
    "            except:\n",
    "                if is_gensim:\n",
    "                    vec.append(model.get_vector('unknown'))\n",
    "                else:\n",
    "                    vec.append(model.get_embed('<UNK>').detach().numpy())\n",
    "\n",
    "        # Append real similarity score (3rd column)\n",
    "        scores_real.append(float(words[2]))\n",
    "\n",
    "        # Compute cosine similarity between the two word vectors\n",
    "        # scores_pred.append(cosine_similarity(np.array(vec[0]).reshape(1, -1), np.array(vec[1]).reshape(1, -1))[0][0])\n",
    "        scores_pred.append(cosine_similarity(np.array(vec[0]), np.array(vec[1])))\n",
    "\n",
    "    # Calculate Spearman rank correlation\n",
    "    return spearmanr(scores_real, scores_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80b0579b-fa4f-4029-9b91-7598e738c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read wordsim_similarity_goldstandard text file and create a list of tuples\n",
    "with open('test_data/wordsim_similarity_goldstandard.txt', 'r') as file:\n",
    "    similarity_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97f79173-fe57-43d2-95c3-d1ae19fb36e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram Model Spearman Correlation: 0.04280092775965694\n"
     ]
    }
   ],
   "source": [
    "# skipgram model\n",
    "spearman_corr_skipgram = evaluate_similarity(similarity_lines, skipgram, is_gensim=False)\n",
    "print(f\"Skipgram Model Spearman Correlation: {spearman_corr_skipgram[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7e853e6-da7d-4438-86f3-6e3c1b5bf261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipgram Negative Sampling Model Spearman Correlation: -0.03984931349350284\n"
     ]
    }
   ],
   "source": [
    "# skipgram negative sampling model\n",
    "spearman_corr_skipgram_neg = evaluate_similarity(similarity_lines, skipgramNeg, is_gensim=False)\n",
    "print(f\"Skipgram Negative Sampling Model Spearman Correlation: {spearman_corr_skipgram_neg[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a96ab7c4-bfa0-476d-828c-5af8817261c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Model Spearman Correlation: 0.10537471804776563\n"
     ]
    }
   ],
   "source": [
    "# glove model\n",
    "spearman_corr_glove = evaluate_similarity(similarity_lines, glove, is_gensim=False)\n",
    "print(f\"Glove Model Spearman Correlation: {spearman_corr_glove[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "695a2e8e-0843-46ad-b9e5-ae244a49d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim Model Spearman Correlation: 0.5962863369934295\n"
     ]
    }
   ],
   "source": [
    "# glove gensim\n",
    "spearman_corr_gensim = evaluate_similarity(similarity_lines, gensim, is_gensim=True)\n",
    "print(f\"Gensim Model Spearman Correlation: {spearman_corr_gensim[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd27cfe-e680-4880-9faa-5a505b4e5f74",
   "metadata": {},
   "source": [
    "### Human Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "527ad091-cc1d-44a2-b66f-c0c205bf4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_human_similarity(analogy_lines, human_scores_file):\n",
    "    \"\"\"\n",
    "    Evaluate similarity scores by comparing analogy line scores and human-provided scores.\n",
    "\n",
    "    Args:\n",
    "        analogy_lines (list): List of strings, where each string is formatted as\n",
    "                              \"word1 word2 similarity_score\".\n",
    "        human_scores_file (str): Path to the file containing human-provided similarity scores.\n",
    "                                 Each line should contain a single numeric value.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Spearman rank correlation (correlation coefficient and p-value).\n",
    "    \"\"\"\n",
    "    scores_real = []  # Store ground truth similarity scores\n",
    "    scores_human = []  # Store human-provided similarity scores\n",
    "\n",
    "    # Read human-provided similarity scores from file and store it in a dictionary\n",
    "    human_scores_dict = {}\n",
    "    with open(human_scores_file, 'r') as file_human:\n",
    "        for line in file_human:\n",
    "            words = line.split()  # Split each line into words\n",
    "            if len(words) >= 3:  # Ensure the line has at least 3 columns\n",
    "                # Use the first two words as the key and the third column (score) as the value\n",
    "                human_scores_dict[(words[0], words[1])] = float(words[2])\n",
    "\n",
    "    # Extract real similarity scores from analogy lines\n",
    "    for line in analogy_lines:\n",
    "        words = line.split()\n",
    "        if len(words) >= 3:  # Ensure valid format\n",
    "            try:\n",
    "                scores_real.append(float(words[2]))\n",
    "            except ValueError:\n",
    "                print(f\"Invalid similarity score in analogy line: {line} (skipping this entry).\")\n",
    "\n",
    "            # Fetch the predicted score from the human input file using the first two words as the key\n",
    "            key = (words[0], words[1])\n",
    "\n",
    "            if key in human_scores_dict:\n",
    "                # Append the corresponding human-provided score to predicted scores\n",
    "                scores_human.append(human_scores_dict[key])\n",
    "            else:\n",
    "                # If no match is found, handle it by appending a default value or handling differently\n",
    "                print(f\"No human score found for: {words[0]} - {words[1]}\")\n",
    "                scores_human.append(0)  # Default value\n",
    "\n",
    "    # Check if the lengths of both lists match\n",
    "    if len(scores_real) != len(scores_human):\n",
    "        raise ValueError(\"Mismatch in the number of real and human-provided scores.\")\n",
    "\n",
    "    # Calculate Spearman correlation\n",
    "    return spearmanr(scores_real, scores_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16306d99-f76c-4516-8470-c0d4228b19cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.9721074309203155, p-value: 1.493074200772165e-128\n"
     ]
    }
   ],
   "source": [
    "human_scores_file = \"test_data/human_scores.txt\"\n",
    "correlation = evaluate_human_similarity(similarity_lines, human_scores_file)\n",
    "print(f\"Spearman Correlation: {correlation[0]}, p-value: {correlation[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
